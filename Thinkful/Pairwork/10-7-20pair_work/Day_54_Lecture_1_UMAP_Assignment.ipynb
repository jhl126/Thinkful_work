{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp37-cp37m-win_amd64.whl (342.5 MB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 425, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 507, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\http\\client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\http\\client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 331, in run\n",
      "    resolver.resolve(requirement_set)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\legacy_resolve.py\", line 177, in resolve\n",
      "    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\legacy_resolve.py\", line 333, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\legacy_resolve.py\", line 282, in _get_abstract_dist_for\n",
      "    abstract_dist = self.preparer.prepare_linked_requirement(req)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 482, in prepare_linked_requirement\n",
      "    hashes=hashes,\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 287, in unpack_url\n",
      "    hashes=hashes,\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 159, in unpack_http_url\n",
      "    link, downloader, temp_dir.path, hashes\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 303, in _download_http_url\n",
      "    for chunk in download.chunks:\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\utils\\ui.py\", line 160, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 39, in response_chunks\n",
      "    decode_content=False,\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 564, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 529, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 430, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"!pip install tensorflow\";\n",
       "                var nbb_formatted_code = \"!pip install tensorflow\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1n-7vLI_UZ47",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d60929f45bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import tensorflow as tf\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\";\n",
       "                var nbb_formatted_code = \"import tensorflow as tf\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM-DVJwyUZ5G"
   },
   "source": [
    "For this assignment we will be using the fashion MNIST dataset.\n",
    "As stated in the original [Github repository](https://github.com/zalandoresearch/fashion-mnist):\n",
    ">Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "One of the easiest ways to load the dataset is by using tf.keras. Our dataset will consist of 3 dimensional numpy arrays with shapes : (samples, rows, columns). In order to use the data with libraries that require 2 dimensional arrays with shapes (samples, features) we will reshape each sample by flattening each image. Instead of having an array of shape (28, 28) for each image we will now have a vector of length 784 (28x28=784).\n",
    "\n",
    "Note that below we only load the trainigng samples which we will use to perform dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EboEQ6H0UZ5I",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (_, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvI-w5wlUZ5P"
   },
   "source": [
    "We keep the class names in the following list and we also create another list named `y_train_labels` which contains the the labels for each sample. We will use these both as labels for our plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAmk4pwKUZ5Q",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "class_dict = dict(enumerate(class_names))\n",
    "\n",
    "y_train_labels = np.vectorize(class_dict.get)(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk9rBbKnUZ56"
   },
   "source": [
    "We also define a function that will print a grid 5x5 of photos from the provided subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHEQLadrUZ58",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_images(X, y):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(X[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[y[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBRXLF7rUZ6L"
   },
   "outputs": [],
   "source": [
    "plot_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qQEVdQoUZ6h"
   },
   "source": [
    "We can use images in python (and other programming languages of course) as arrays/matrices. In python a byte image of 28x28 will be represented by a numpy array of shape (28,28) with each pixel/cell having a value in the range [0, 255] with 0 being black and 255 white. The values between represent shades of gray. On the same note if we had an RBG image with colors, the same array would be a 3-dimensional numpy array of shape (28, 28, 3) where each pixel is represented by three values in the range [0, 255] for each color (Red, Green, Blue).\n",
    "\n",
    "We have seen feature scaling in the past. In order to be able to use our images with methods that are scale sensitive we divide all values by 255, thus bringing everything in the [0, 1] range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0w-QzzLUZ6l",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DNh1OQoUZ6v"
   },
   "source": [
    "Scikit learn methods require 2-dimensional datasets (number_of_rows, number_of_features). We tranform each image from 28 x 28 pixels to a flat array of 784 length. To find the number of features we multiply the last two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxPLdLpjUZ6-",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_features = X_train.shape[1] * X_train.shape[2]\n",
    "X_train_reshaped = X_train.reshape(-1, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_s5tdmmUZ7U"
   },
   "source": [
    "When we plot images we will require to reshape them back to 28x28 images.\n",
    "\n",
    "Also we select just a subset (1000) of our data samples and perform our exercises on this one in order to speed up execution, as our purpose is to showcase this. For more accurate/better results, we would need to do this on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0yMMVR1UZ7Y",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_sub = X_train_reshaped[:1000]\n",
    "y_train_labels_sub = y_train_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzqBO8__UZ7u",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Run PCA and keep the first two components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LF8MZjiUZ78",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot reduced data in two dimensions using seaborn scatterplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bclon47XUZ8x"
   },
   "source": [
    "We can now inverse transform the reduced data. This means that we transform it back to the original space by using only the number of components we run PCA on (2 in our case). This will let us understand what dimensionality reduction really means. We keep a subset of these latent features that maximize the explained variance. With these plots we get an idea of what \"maximum explained variance\" actually means. We get images that vaguely look like our initial articles, but without the details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrTNEr8qUZ80",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inversed = pca.inverse_transform(projected).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uy0hvLFkUZ8-",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_images(inversed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5fRKRUDHSIt"
   },
   "source": [
    "Create t-SNE models with different amounts of perplexity (try between single and triple digits?) and plot their reduced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ateVgqZUZ-3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "    # Run TSNE for each of these perplexity values and transform X_train_sub\n",
    "    \n",
    "    \n",
    "    # Plot reduced features in two dimensions using seaborn scatterplot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxeWGukaUZ_l"
   },
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIVTjU5_HhKt"
   },
   "source": [
    "Create UMAP models with different numbers of neighbors (try between single and triple digits again) and plot their reduced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmVbY8pTUaAL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "\n",
    "    # Run UMAP for each of these n_neighbors values and transform X_train_sub\n",
    "    \n",
    "\n",
    "    # Plot reduced features in two dimensions using seaborn scatterplot\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L__oD61H9_q"
   },
   "source": [
    "What have you observed? How would you be able to use these reduced features in further study?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpJwQ7zDIWmg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 54 Lecture 1 UMAP Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black\n",
    "\n",
    "from nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data to be Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# regex syntax\\nPATH = \\\"./subject/physics_biology_geography_accounts subject training data for text classification/train_data_final\\\"\\n\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\nCAT_PATTERN = r\\\"([\\\\w_\\\\w]+)/.*\\\"\\n\\ncorpus = CategorizedPlaintextCorpusReader(PATH, DOC_PATTERN, cat_pattern=CAT_PATTERN)\";\n",
       "                var nbb_formatted_code = \"# regex syntax\\nPATH = \\\"./subject/physics_biology_geography_accounts subject training data for text classification/train_data_final\\\"\\n\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\nCAT_PATTERN = r\\\"([\\\\w_\\\\w]+)/.*\\\"\\n\\ncorpus = CategorizedPlaintextCorpusReader(PATH, DOC_PATTERN, cat_pattern=CAT_PATTERN)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regex syntax\n",
    "# Data is obtained from this kaggle link:\n",
    "# https://www.kaggle.com/deepak711/4-subject-data-text-classification\n",
    "PATH = \"./subject/physics_biology_geography_accounts subject training data for text classification/train_data_final\"\n",
    "\n",
    "DOC_PATTERN = r\".*\\.txt\"\n",
    "CAT_PATTERN = r\"([\\w_\\w]+)/.*\"\n",
    "\n",
    "corpus = CategorizedPlaintextCorpusReader(PATH, DOC_PATTERN, cat_pattern=CAT_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Splitting up the data by documents and categories\\ndocs = [corpus.raw(fileid) for fileid in corpus.fileids()]\\ncategories = [corpus.categories(fileid)[0] for fileid in corpus.fileids()]\";\n",
       "                var nbb_formatted_code = \"# Splitting up the data by documents and categories\\ndocs = [corpus.raw(fileid) for fileid in corpus.fileids()]\\ncategories = [corpus.categories(fileid)[0] for fileid in corpus.fileids()]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting up the data by documents and categories\n",
    "docs = [corpus.raw(fileid) for fileid in corpus.fileids()]\n",
    "categories = [corpus.categories(fileid)[0] for fileid in corpus.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"categories\";\n",
       "                var nbb_formatted_code = \"categories\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Creating a function to help clean up data\\ndef preprocess(docs):\\n    lemmatizer = WordNetLemmatizer()\\n    stemmer = SnowballStemmer(\\\"english\\\")\\n    preprocessed = []\\n    for doc in docs:\\n        tokenized = word_tokenize(doc)\\n        cleaned = [\\n            stemmer.stem(lemmatizer.lemmatize(token.lower()))\\n            for token in tokenized\\n            if not token.lower() in stopwords.words(\\\"english\\\")\\n            if token.isalpha()\\n        ]\\n        untokenized = \\\" \\\".join(cleaned)\\n        preprocessed.append(untokenized)\\n    return preprocessed\";\n",
       "                var nbb_formatted_code = \"# Creating a function to help clean up data\\ndef preprocess(docs):\\n    lemmatizer = WordNetLemmatizer()\\n    stemmer = SnowballStemmer(\\\"english\\\")\\n    preprocessed = []\\n    for doc in docs:\\n        tokenized = word_tokenize(doc)\\n        cleaned = [\\n            stemmer.stem(lemmatizer.lemmatize(token.lower()))\\n            for token in tokenized\\n            if not token.lower() in stopwords.words(\\\"english\\\")\\n            if token.isalpha()\\n        ]\\n        untokenized = \\\" \\\".join(cleaned)\\n        preprocessed.append(untokenized)\\n    return preprocessed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a function to help clean up data\n",
    "def preprocess(docs):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    preprocessed = []\n",
    "    for doc in docs:\n",
    "        tokenized = word_tokenize(doc)\n",
    "        cleaned = [\n",
    "            stemmer.stem(lemmatizer.lemmatize(token.lower()))\n",
    "            for token in tokenized\n",
    "            if not token.lower() in stopwords.words(\"english\")\n",
    "            if token.isalpha()\n",
    "        ]\n",
    "        untokenized = \" \".join(cleaned)\n",
    "        preprocessed.append(untokenized)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"preprocessed = preprocess(docs)\";\n",
       "                var nbb_formatted_code = \"preprocessed = preprocess(docs)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed = preprocess(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"X_train, X_test, y_train, y_test = tts(docs, categories, test_size=0.2)\";\n",
       "                var nbb_formatted_code = \"X_train, X_test, y_train, y_test = tts(docs, categories, test_size=0.2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = tts(docs, categories, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"rf\\\", RandomForestClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"rf\\\", RandomForestClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"rf\", RandomForestClassifier())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    accounts       1.00      1.00      1.00        57\n",
      "     biology       0.92      1.00      0.96       135\n",
      "   geography       1.00      0.25      0.40        16\n",
      "     physics       0.99      1.00      1.00       150\n",
      "\n",
      "    accuracy                           0.97       358\n",
      "   macro avg       0.98      0.81      0.84       358\n",
      "weighted avg       0.97      0.97      0.96       358\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122362258333558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data with KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"knn\\\", KNeighborsClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"knn\\\", KNeighborsClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"knn\\\", KNeighborsClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"knn\\\", KNeighborsClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"knn\", KNeighborsClassifier())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    accounts       1.00      1.00      1.00        57\n",
      "     biology       0.97      0.99      0.98       135\n",
      "   geography       1.00      0.56      0.72        16\n",
      "     physics       0.97      1.00      0.99       150\n",
      "\n",
      "    accuracy                           0.98       358\n",
      "   macro avg       0.99      0.89      0.92       358\n",
      "weighted avg       0.98      0.98      0.98       358\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607658937850328"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"svc\", SVC())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    accounts       1.00      1.00      1.00        57\n",
      "     biology       0.94      1.00      0.97       135\n",
      "   geography       1.00      0.50      0.67        16\n",
      "     physics       0.99      0.99      0.99       150\n",
      "\n",
      "    accuracy                           0.97       358\n",
      "   macro avg       0.98      0.87      0.91       358\n",
      "weighted avg       0.98      0.97      0.97       358\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391105524011515"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclustions\n",
    "\n",
    "The models are all able to predict the subjects of the documents pretty accurately, all having an f1 score of 0.80 or higher. The KNearestNeighbor Classifier performed the best with having an f1 score of around 0.86. Some ways to improve this model could be changing hyper parameters on each of the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nfrom nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\\n\\nfrom nltk import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom sklearn.pipeline import Pipeline\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\n\\nfrom sklearn.model_selection import train_test_split as tts\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics import classification_report\\n\\nfrom sklearn.model_selection import cross_val_score\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black\n",
    "\n",
    "from nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data to be Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# regex syntax\\n# Data is obtained from this kaggle link:\\n# https://www.kaggle.com/deepak711/4-subject-data-text-classification\\nPATH = \\\"./subject/physics_biology_geography_accounts subject training data for text classification/train_data_final\\\"\\n\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\nCAT_PATTERN = r\\\"([\\\\w_\\\\w]+)/.*\\\"\\n\\ncorpus = CategorizedPlaintextCorpusReader(PATH, DOC_PATTERN, cat_pattern=CAT_PATTERN)\";\n",
       "                var nbb_formatted_code = \"# regex syntax\\n# Data is obtained from this kaggle link:\\n# https://www.kaggle.com/deepak711/4-subject-data-text-classification\\nPATH = \\\"./subject/physics_biology_geography_accounts subject training data for text classification/train_data_final\\\"\\n\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\nCAT_PATTERN = r\\\"([\\\\w_\\\\w]+)/.*\\\"\\n\\ncorpus = CategorizedPlaintextCorpusReader(PATH, DOC_PATTERN, cat_pattern=CAT_PATTERN)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regex syntax\n",
    "# Data is obtained from this kaggle link:\n",
    "# https://www.kaggle.com/deepak711/4-subject-data-text-classification\n",
    "PATH = \"./subject/physics_biology_geography_accounts subject training data for text classification/train_data_final\"\n",
    "\n",
    "DOC_PATTERN = r\".*\\.txt\"\n",
    "CAT_PATTERN = r\"([\\w_\\w]+)/.*\"\n",
    "\n",
    "corpus = CategorizedPlaintextCorpusReader(PATH, DOC_PATTERN, cat_pattern=CAT_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Splitting up the data by documents and categories\\ndocs = [corpus.raw(fileid) for fileid in corpus.fileids()]\\ncategories = [corpus.categories(fileid)[0] for fileid in corpus.fileids()]\";\n",
       "                var nbb_formatted_code = \"# Splitting up the data by documents and categories\\ndocs = [corpus.raw(fileid) for fileid in corpus.fileids()]\\ncategories = [corpus.categories(fileid)[0] for fileid in corpus.fileids()]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting up the data by documents and categories\n",
    "docs = [corpus.raw(fileid) for fileid in corpus.fileids()]\n",
    "categories = [corpus.categories(fileid)[0] for fileid in corpus.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'accounts',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'biology',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " 'geography',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"categories\";\n",
       "                var nbb_formatted_code = \"categories\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Creating a function to help clean up data\\ndef preprocess(docs):\\n    lemmatizer = WordNetLemmatizer()\\n    stemmer = SnowballStemmer(\\\"english\\\")\\n    preprocessed = []\\n    for doc in docs:\\n        tokenized = word_tokenize(doc)\\n        cleaned = [\\n            stemmer.stem(lemmatizer.lemmatize(token.lower()))\\n            for token in tokenized\\n            if not token.lower() in stopwords.words(\\\"english\\\")\\n            if token.isalpha()\\n        ]\\n        untokenized = \\\" \\\".join(cleaned)\\n        preprocessed.append(untokenized)\\n    return preprocessed\";\n",
       "                var nbb_formatted_code = \"# Creating a function to help clean up data\\ndef preprocess(docs):\\n    lemmatizer = WordNetLemmatizer()\\n    stemmer = SnowballStemmer(\\\"english\\\")\\n    preprocessed = []\\n    for doc in docs:\\n        tokenized = word_tokenize(doc)\\n        cleaned = [\\n            stemmer.stem(lemmatizer.lemmatize(token.lower()))\\n            for token in tokenized\\n            if not token.lower() in stopwords.words(\\\"english\\\")\\n            if token.isalpha()\\n        ]\\n        untokenized = \\\" \\\".join(cleaned)\\n        preprocessed.append(untokenized)\\n    return preprocessed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a function to help clean up data\n",
    "def preprocess(docs):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    preprocessed = []\n",
    "    for doc in docs:\n",
    "        tokenized = word_tokenize(doc)\n",
    "        cleaned = [\n",
    "            stemmer.stem(lemmatizer.lemmatize(token.lower()))\n",
    "            for token in tokenized\n",
    "            if not token.lower() in stopwords.words(\"english\")\n",
    "            if token.isalpha()\n",
    "        ]\n",
    "        untokenized = \" \".join(cleaned)\n",
    "        preprocessed.append(untokenized)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"preprocessed = preprocess(docs)\";\n",
       "                var nbb_formatted_code = \"preprocessed = preprocess(docs)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed = preprocess(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"X_train, X_test, y_train, y_test = tts(preprocessed, categories, test_size=0.2)\";\n",
       "                var nbb_formatted_code = \"X_train, X_test, y_train, y_test = tts(preprocessed, categories, test_size=0.2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = tts(preprocessed, categories, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"rf\\\", RandomForestClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"rf\\\", RandomForestClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"rf\", RandomForestClassifier())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    accounts       1.00      1.00      1.00        60\n",
      "     biology       0.94      1.00      0.97       126\n",
      "   geography       1.00      0.30      0.46        20\n",
      "     physics       0.96      1.00      0.98       152\n",
      "\n",
      "    accuracy                           0.96       358\n",
      "   macro avg       0.98      0.82      0.85       358\n",
      "weighted avg       0.96      0.96      0.95       358\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157410090737635"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data with KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"knn\\\", KNeighborsClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"knn\\\", KNeighborsClassifier())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"knn\", KNeighborsClassifier())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    accounts       0.97      1.00      0.98        60\n",
      "     biology       0.98      0.98      0.98       126\n",
      "   geography       0.89      0.80      0.84        20\n",
      "     physics       0.99      0.98      0.98       152\n",
      "\n",
      "    accuracy                           0.97       358\n",
      "   macro avg       0.95      0.94      0.95       358\n",
      "weighted avg       0.97      0.97      0.97       358\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607658937850328"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"pipe = Pipeline([(\\\"tfidf\\\", TfidfVectorizer()), (\\\"svc\\\", SVC())])\\npipe.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"svc\", SVC())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    accounts       1.00      0.97      0.98        60\n",
      "     biology       0.95      1.00      0.98       126\n",
      "   geography       1.00      0.70      0.82        20\n",
      "     physics       0.99      1.00      0.99       152\n",
      "\n",
      "    accuracy                           0.98       358\n",
      "   macro avg       0.99      0.92      0.94       358\n",
      "weighted avg       0.98      0.98      0.98       358\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_formatted_code = \"pred = pipe.predict(X_test)\\nprint(classification_report(y_test, pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_formatted_code = \"scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\\\"f1_macro\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, preprocessed, categories, cv=10, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391105524011515"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"scores.mean()\";\n",
       "                var nbb_formatted_code = \"scores.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclustions\n",
    "\n",
    "The models are all able to predict the subjects of the documents pretty accurately, all having an f1 score of 0.80 or higher. The KNearestNeighbor Classifier performed the best with having an f1 score of around 0.86. Some ways to improve this model could be changing hyper parameters on each of the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

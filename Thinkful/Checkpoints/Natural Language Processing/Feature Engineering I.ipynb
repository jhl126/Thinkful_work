{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\jlim7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split,GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split,GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split,GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split,GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split,GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nimport numpy as np\\nimport pandas as pd\\nimport sklearn\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nimport spacy\\nimport re\\nimport nltk\\nfrom nltk.corpus import gutenberg\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nnltk.download(\\\"gutenberg\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (45.2.0.post20200210)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.42.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jlim7\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.2.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[x] Couldn't link model to 'en'\n",
      "Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "permissions and try re-running the command as admin, or use a virtualenv. You\n",
      "can still import the model as a module and call its load() method, or create the\n",
      "symlink manually.\n",
      "C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "[!] Download successful but linking failed\n",
      "Creating a shortcut link for 'en' didn't work (maybe you don't have admin\n",
      "permissions?), but you can still load the model via its full package name: nlp =\n",
      "spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You do not have sufficient privilege to perform this operation.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"!python -m spacy download en\";\n",
       "                var nbb_formatted_code = \"!python -m spacy download en\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Utility function for standard text cleaning\\ndef text_cleaner(text):\\n    # Visual inspection identifies a form of punctuation that spaCy doesn't\\n    # recognize: the double dash '--'. Better get rid of it now!\\n    text = re.sub(r'--',' ',text)\\n    text = re.sub(\\\"[\\\\[].*?[\\\\]]\\\", \\\"\\\", text)\\n    text = re.sub(r\\\"(\\\\b|\\\\s+\\\\-?|^\\\\-?)(\\\\d+|\\\\d*\\\\.\\\\d+)\\\\b\\\", \\\" \\\", text)\\n    text = ' '.join(text.split())\\n    return text\";\n",
       "                var nbb_formatted_code = \"# Utility function for standard text cleaning\\ndef text_cleaner(text):\\n    # Visual inspection identifies a form of punctuation that spaCy doesn't\\n    # recognize: the double dash '--'. Better get rid of it now!\\n    text = re.sub(r\\\"--\\\", \\\" \\\", text)\\n    text = re.sub(\\\"[\\\\[].*?[\\\\]]\\\", \\\"\\\", text)\\n    text = re.sub(r\\\"(\\\\b|\\\\s+\\\\-?|^\\\\-?)(\\\\d+|\\\\d*\\\\.\\\\d+)\\\\b\\\", \\\" \\\", text)\\n    text = \\\" \\\".join(text.split())\\n    return text\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation that spaCy doesn't\n",
    "    # recognize: the double dash '--'. Better get rid of it now!\n",
    "    text = re.sub(r\"--\", \" \", text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Load and clean the data\\npersuasion = gutenberg.raw('austen-persuasion.txt')\\nalice = gutenberg.raw('carroll-alice.txt')\\n\\n# The chapter indicator is idiosyncratic\\npersuasion = re.sub(r'Chapter \\\\d+', '', persuasion)\\nalice = re.sub(r'CHAPTER .*', '', alice)\\n    \\nalice = text_cleaner(alice)\\npersuasion = text_cleaner(persuasion)\";\n",
       "                var nbb_formatted_code = \"# Load and clean the data\\npersuasion = gutenberg.raw(\\\"austen-persuasion.txt\\\")\\nalice = gutenberg.raw(\\\"carroll-alice.txt\\\")\\n\\n# The chapter indicator is idiosyncratic\\npersuasion = re.sub(r\\\"Chapter \\\\d+\\\", \\\"\\\", persuasion)\\nalice = re.sub(r\\\"CHAPTER .*\\\", \\\"\\\", alice)\\n\\nalice = text_cleaner(alice)\\npersuasion = text_cleaner(persuasion)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and clean the data\n",
    "persuasion = gutenberg.raw(\"austen-persuasion.txt\")\n",
    "alice = gutenberg.raw(\"carroll-alice.txt\")\n",
    "\n",
    "# The chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r\"Chapter \\d+\", \"\", persuasion)\n",
    "alice = re.sub(r\"CHAPTER .*\", \"\", alice)\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"nlp = spacy.load('en_core_web_sm')\\nalice_doc = nlp(alice)\\npersuasion_doc = nlp(persuasion)\";\n",
       "                var nbb_formatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\nalice_doc = nlp(alice)\\npersuasion_doc = nlp(persuasion)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Group into sentences\\nalice_sents = [[sent, \\\"Carroll\\\"] for sent in alice_doc.sents]\\npersuasion_sents = [[sent, \\\"Austen\\\"] for sent in persuasion_doc.sents]\\n\\n# Combine the sentences from the two novels into one DataFrame\\nsentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\\\"text\\\", \\\"author\\\"])\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"# Group into sentences\\nalice_sents = [[sent, \\\"Carroll\\\"] for sent in alice_doc.sents]\\npersuasion_sents = [[sent, \\\"Austen\\\"] for sent in persuasion_doc.sents]\\n\\n# Combine the sentences from the two novels into one DataFrame\\nsentences = pd.DataFrame(alice_sents + persuasion_sents, columns=[\\\"text\\\", \\\"author\\\"])\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group into sentences\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one DataFrame\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns=[\"text\", \"author\"])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Get rid of stop words and punctuation,\\n# and lemmatize the tokens\\nfor i, sentence in enumerate(sentences[\\\"text\\\"]):\\n    sentences.loc[i, \\\"text\\\"] = \\\" \\\".join(\\n        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])\";\n",
       "                var nbb_formatted_code = \"# Get rid of stop words and punctuation,\\n# and lemmatize the tokens\\nfor i, sentence in enumerate(sentences[\\\"text\\\"]):\\n    sentences.loc[i, \\\"text\\\"] = \\\" \\\".join(\\n        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get rid of stop words and punctuation,\n",
    "# and lemmatize the tokens\n",
    "for i, sentence in enumerate(sentences[\"text\"]):\n",
    "    sentences.loc[i, \"text\"] = \" \".join(\n",
    "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word')\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\")\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word')\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\")\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding other modeling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9354838709677419\n",
      "\n",
      "Test set score: 0.8761651131824234\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.9795797573246523\n",
      "\n",
      "Test set score: 0.8508655126498003\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8514353358981948\n",
      "\n",
      "Test set score: 0.8362183754993342\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# original models\\n\\nY = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# original models\\n\\nY = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# original models\\n\\nY = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# original models\\n\\nY = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# original models\\n\\nY = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# original models\\n\\nY = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original models\n",
    "\n",
    "Y = sentences[\"author\"]\n",
    "X = np.array(sentences.drop([\"text\", \"author\"], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=123\n",
    ")\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print(\"Training set score:\", lr.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print(\"Training set score:\", rfc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print(\"Training set score:\", gbc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------KNearestNeighbors Scores----------------------\n",
      "Training set score: 0.8144421426457532\n",
      "\n",
      "Test set score: 0.746560142032845\n",
      "----------------------Support Vector Classifier Scores----------------------\n",
      "Training set score: 0.9121041728321989\n",
      "\n",
      "Test set score: 0.8477585441633377\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"# new models\\n\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new models\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------KNearestNeighbors Scores----------------------\")\n",
    "print(\"Training set score:\", knn.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", knn.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Support Vector Classifier Scores----------------------\")\n",
    "print(\"Training set score:\", svc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using both 1-gram and 2-gram features together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>29th</th>\n",
       "      <th>29th september</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abbreviation living</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abdication neighbour</th>\n",
       "      <th>abide</th>\n",
       "      <th>abide consequence</th>\n",
       "      <th>abide figure</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand australia</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealous officer</th>\n",
       "      <th>zealous subject</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zealously discharge</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzag go</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st  29th  29th september  abbreviation  abbreviation living  abdication  \\\n",
       "0    0     0               0             0                    0           0   \n",
       "1    0     0               0             0                    0           0   \n",
       "2    0     0               0             0                    0           0   \n",
       "3    0     0               0             0                    0           0   \n",
       "4    0     0               0             0                    0           0   \n",
       "\n",
       "   abdication neighbour  abide  abide consequence  abide figure  ...  \\\n",
       "0                     0      0                  0             0  ...   \n",
       "1                     0      0                  0             0  ...   \n",
       "2                     0      0                  0             0  ...   \n",
       "3                     0      0                  0             0  ...   \n",
       "4                     0      0                  0             0  ...   \n",
       "\n",
       "   zealand australia  zealous  zealous officer  zealous subject  zealously  \\\n",
       "0                  0        0                0                0          0   \n",
       "1                  0        0                0                0          0   \n",
       "2                  0        0                0                0          0   \n",
       "3                  0        0                0                0          0   \n",
       "4                  0        0                0                0          0   \n",
       "\n",
       "   zealously discharge  zigzag  zigzag go  \\\n",
       "0                    0       0          0   \n",
       "1                    0       0          0   \n",
       "2                    0       0          0   \n",
       "3                    0       0          0   \n",
       "4                    0       0          0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2             remarkable Alice think way hear Rabbit  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                            oh dear  Carroll  \n",
       "\n",
       "[5 rows x 35386 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\", ngram_range=(1, 2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\", ngram_range=(1, 2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\", ngram_range=(1, 2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\", ngram_range=(1, 2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"vectorizer = CountVectorizer(analyzer=\\\"word\\\", ngram_range=(1, 2))\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\nbow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([bow_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\", ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9556081680970702\n",
      "\n",
      "Test set score: 0.875277407900577\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.9795797573246523\n",
      "\n",
      "Test set score: 0.8641810918774967\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8490677715300384\n",
      "\n",
      "Test set score: 0.833555259653795\n",
      "----------------------KNearestNeighbors Scores----------------------\n",
      "Training set score: 0.8097070139094407\n",
      "\n",
      "Test set score: 0.7305814469596094\n",
      "----------------------Support Vector Classifier Scores----------------------\n",
      "Training set score: 0.9073690440958864\n",
      "\n",
      "Test set score: 0.8246782068353307\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\nknn = KNeighborsClassifier()\\nsvc = SVC()\\n\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\nknn.fit(X_train, y_train)\\nsvc.fit(X_train, y_train)\\n\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\\n\\nprint(\\\"----------------------KNearestNeighbors Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", knn.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", knn.score(X_test, y_test))\\n\\nprint(\\\"----------------------Support Vector Classifier Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", svc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", svc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = sentences[\"author\"]\n",
    "X = np.array(sentences.drop([\"text\", \"author\"], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=123\n",
    ")\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print(\"Training set score:\", lr.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print(\"Training set score:\", rfc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print(\"Training set score:\", gbc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", gbc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------KNearestNeighbors Scores----------------------\")\n",
    "print(\"Training set score:\", knn.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", knn.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Support Vector Classifier Scores----------------------\")\n",
    "print(\"Training set score:\", svc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", svc.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

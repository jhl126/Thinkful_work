{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nfrom tensorflow.keras.datasets import mnist\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nfrom tensorflow.keras.datasets import mnist\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\ninput_dim = 784  # 28*28\\noutput_dim = nb_classes = 10\\nbatch_size = 128\\nnb_epoch = 20\\n\\nX_train = X_train.reshape(60000, input_dim)\\nX_test = X_test.reshape(10000, input_dim)\\nX_train = X_train.astype(\\\"float32\\\")\\nX_test = X_test.astype(\\\"float32\\\")\\nX_train /= 255\\nX_test /= 255\";\n",
       "                var nbb_formatted_code = \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\ninput_dim = 784  # 28*28\\noutput_dim = nb_classes = 10\\nbatch_size = 128\\nnb_epoch = 20\\n\\nX_train = X_train.reshape(60000, input_dim)\\nX_test = X_test.reshape(10000, input_dim)\\nX_train = X_train.astype(\\\"float32\\\")\\nX_test = X_test.astype(\\\"float32\\\")\\nX_train /= 255\\nX_test /= 255\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "input_dim = 784  # 28*28\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"y_train = to_categorical(y_train, nb_classes)\\ny_test = to_categorical(y_test, nb_classes)\";\n",
       "                var nbb_formatted_code = \"y_train = to_categorical(y_train, nb_classes)\\ny_test = to_categorical(y_test, nb_classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, nb_classes)\n",
    "y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"model = Sequential()\\nmodel.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"tanh\\\"))\\nmodel.add(Dense(64, activation=\\\"tanh\\\"))\\nmodel.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_formatted_code = \"model = Sequential()\\nmodel.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"tanh\\\"))\\nmodel.add(Dense(64, activation=\\\"tanh\\\"))\\nmodel.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"model.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\";\n",
       "                var nbb_formatted_code = \"model.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229DEBF1828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229DEBF1828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0634 - accuracy: 0.7306\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5427 - accuracy: 0.8640\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.4326 - accuracy: 0.8855\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3802 - accuracy: 0.8960\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3482 - accuracy: 0.9035\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3257 - accuracy: 0.9091\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3086 - accuracy: 0.9135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2947 - accuracy: 0.9169\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2830 - accuracy: 0.9202\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2728 - accuracy: 0.9228\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2637 - accuracy: 0.9251\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2556 - accuracy: 0.9271\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2480 - accuracy: 0.9297\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2412 - accuracy: 0.9315\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2346 - accuracy: 0.9330\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2286 - accuracy: 0.9352\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2229 - accuracy: 0.9368\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2175 - accuracy: 0.9381\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2125 - accuracy: 0.9399\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2076 - accuracy: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229debfef88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_formatted_code = \"model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.20654038635492325\n",
      "Test accuracy: 0.9416\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"score = model.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_formatted_code = \"score = model.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"model2 = Sequential()\\nmodel2.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"sigmoid\\\"))\\nmodel2.add(Dense(64, activation=\\\"sigmoid\\\"))\\nmodel2.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_formatted_code = \"model2 = Sequential()\\nmodel2.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"sigmoid\\\"))\\nmodel2.add(Dense(64, activation=\\\"sigmoid\\\"))\\nmodel2.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_dim=X_train.shape[1], activation=\"sigmoid\"))\n",
    "model2.add(Dense(64, activation=\"sigmoid\"))\n",
    "model2.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EA2BCA68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EA2BCA68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2913 - accuracy: 0.1466\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 2.2339 - accuracy: 0.3349\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 2.1714 - accuracy: 0.4916\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 2.0837 - accuracy: 0.5784\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.9580 - accuracy: 0.6314\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.7893 - accuracy: 0.6529\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.5936 - accuracy: 0.6732\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.4022 - accuracy: 0.6980\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.2376 - accuracy: 0.7215\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.1041 - accuracy: 0.7467\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9970 - accuracy: 0.7663\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9103 - accuracy: 0.7833\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8392 - accuracy: 0.7973\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7800 - accuracy: 0.8093\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7301 - accuracy: 0.8205\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.6876 - accuracy: 0.8296\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.6510 - accuracy: 0.8375\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.6193 - accuracy: 0.8448\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5918 - accuracy: 0.8512\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.5676 - accuracy: 0.8565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229ea773888>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"model2.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\\nmodel2.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_formatted_code = \"model2.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\\nmodel2.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model2.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.544653081703186\n",
      "Test accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"score = model2.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_formatted_code = \"score = model2.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"model3 = Sequential()\\nmodel3.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"relu\\\"))\\nmodel3.add(Dense(64, activation=\\\"relu\\\"))\\nmodel3.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_formatted_code = \"model3 = Sequential()\\nmodel3.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"relu\\\"))\\nmodel3.add(Dense(64, activation=\\\"relu\\\"))\\nmodel3.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model3.add(Dense(64, activation=\"relu\"))\n",
    "model3.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EBE5A5E8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EBE5A5E8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3614 - accuracy: 0.6573\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5332 - accuracy: 0.8657\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3990 - accuracy: 0.8919\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3476 - accuracy: 0.9028\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.3176 - accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2965 - accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2800 - accuracy: 0.9201\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2664 - accuracy: 0.9247\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2543 - accuracy: 0.9276\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2437 - accuracy: 0.9310\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2345 - accuracy: 0.9334\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2258 - accuracy: 0.9357\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2181 - accuracy: 0.9378\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2104 - accuracy: 0.9398\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2036 - accuracy: 0.9417\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1971 - accuracy: 0.9437\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1908 - accuracy: 0.9460\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1851 - accuracy: 0.9477\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1796 - accuracy: 0.9492\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1743 - accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229ebd67948>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"model3.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\\nmodel3.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_formatted_code = \"model3.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\\nmodel3.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model3.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.17536006162017584\n",
      "Test accuracy: 0.9486\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"score = model3.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_formatted_code = \"score = model3.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of each model. Which activation function performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model using ReLU activation function performed better than both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"model4 = Sequential()\\nmodel4.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"tanh\\\"))\\nmodel4.add(Dense(64, activation=\\\"tanh\\\"))\\nmodel4.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_formatted_code = \"model4 = Sequential()\\nmodel4.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"tanh\\\"))\\nmodel4.add(Dense(64, activation=\\\"tanh\\\"))\\nmodel4.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(128, input_dim=X_train.shape[1], activation=\"tanh\"))\n",
    "model4.add(Dense(64, activation=\"tanh\"))\n",
    "model4.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\jlim7\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1430: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EBDD78B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EBDD78B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9799 - accuracy: 0.4109\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7841 - accuracy: 0.6710\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.6049 - accuracy: 0.7808\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.4769 - accuracy: 0.8355\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3966 - accuracy: 0.8601\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.3474 - accuracy: 0.8740\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3149 - accuracy: 0.8827\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2916 - accuracy: 0.8886\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2739 - accuracy: 0.8937\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2598 - accuracy: 0.8976\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2483 - accuracy: 0.9008\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2385 - accuracy: 0.9039\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2300 - accuracy: 0.9064\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2226 - accuracy: 0.9092\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2163 - accuracy: 0.9112\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2105 - accuracy: 0.9132\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2053 - accuracy: 0.9147\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2005 - accuracy: 0.9165\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1962 - accuracy: 0.9179\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1922 - accuracy: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229ebb5fd88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"model4.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\nmodel4.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_formatted_code = \"model4.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\nmodel4.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4.compile(optimizer=\"sgd\", loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "model4.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.18486185675263406\n",
      "Test accuracy: 0.9222\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"score = model4.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_formatted_code = \"score = model4.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model4.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"model5 = Sequential()\\nmodel5.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"sigmoid\\\"))\\nmodel5.add(Dense(64, activation=\\\"sigmoid\\\"))\\nmodel5.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_formatted_code = \"model5 = Sequential()\\nmodel5.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"sigmoid\\\"))\\nmodel5.add(Dense(64, activation=\\\"sigmoid\\\"))\\nmodel5.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(128, input_dim=X_train.shape[1], activation=\"sigmoid\"))\n",
    "model5.add(Dense(64, activation=\"sigmoid\"))\n",
    "model5.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EDC7CCA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EDC7CCA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0117 - accuracy: 0.1130\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0030 - accuracy: 0.1795\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0023 - accuracy: 0.2377\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.0018 - accuracy: 0.2988\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0013 - accuracy: 0.3544\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0009 - accuracy: 0.4038\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0005 - accuracy: 0.4440\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0001 - accuracy: 0.4787\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9998 - accuracy: 0.5080\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9995 - accuracy: 0.5339\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9992 - accuracy: 0.5569\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9989 - accuracy: 0.5766\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9986 - accuracy: 0.5944\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9984 - accuracy: 0.6109\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9981 - accuracy: 0.6246\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9978 - accuracy: 0.6373\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9976 - accuracy: 0.6487\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9973 - accuracy: 0.6591\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9971 - accuracy: 0.6684\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9968 - accuracy: 0.6763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229edcbf488>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"model5.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\nmodel5.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_formatted_code = \"model5.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\nmodel5.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model5.compile(optimizer=\"sgd\", loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "model5.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9964910932540894\n",
      "Test accuracy: 0.6985\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"score = model5.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_formatted_code = \"score = model5.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model5.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"model6 = Sequential()\\nmodel6.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"relu\\\"))\\nmodel6.add(Dense(64, activation=\\\"relu\\\"))\\nmodel6.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_formatted_code = \"model6 = Sequential()\\nmodel6.add(Dense(128, input_dim=X_train.shape[1], activation=\\\"relu\\\"))\\nmodel6.add(Dense(64, activation=\\\"relu\\\"))\\nmodel6.add(Dense(10, activation=\\\"softmax\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model6.add(Dense(64, activation=\"relu\"))\n",
    "model6.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EE41B828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000229EE41B828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0167 - accuracy: 0.2574\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9901 - accuracy: 0.4858\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9295 - accuracy: 0.6013\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7906 - accuracy: 0.6799\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.5997 - accuracy: 0.7891\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.4443 - accuracy: 0.8530\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3504 - accuracy: 0.8729\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.3007 - accuracy: 0.8845\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2707 - accuracy: 0.8921\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2500 - accuracy: 0.8979\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2350 - accuracy: 0.9021\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2231 - accuracy: 0.9060\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2135 - accuracy: 0.9094\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2053 - accuracy: 0.9121\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.1983 - accuracy: 0.9150\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1921 - accuracy: 0.9174\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.1867 - accuracy: 0.9191\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.1818 - accuracy: 0.9213s - loss: 0.1825 - accu\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1772 - accuracy: 0.9231\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1730 - accuracy: 0.9241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229ee432708>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"model6.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\nmodel6.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_formatted_code = \"model6.compile(optimizer=\\\"sgd\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\nmodel6.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model6.compile(optimizer=\"sgd\", loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "model6.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1680106873214245\n",
      "Test accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"score = model6.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_formatted_code = \"score = model6.evaluate(X_test, y_test, verbose=0)\\nprint(\\\"Test score:\\\", score[0])\\nprint(\\\"Test accuracy:\\\", score[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model6.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of each model with the result of the same model from the previous task. Which loss function performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the model using ReLU activation function performed the best, but accuracy dropped when using categorical_hinge loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
